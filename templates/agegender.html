<!DOCTYPE html>
<html lang="en">

<!-- HEAD -->
<head>
    {% include "head.html" %}
    <title>EPIC Age & Gender Classifier</title>
</head>

<!-- BODY -->
<body>
    {% include "navbar.html" %}

    <div class="container-fluid align-items-center" id="modelContainer">
        <img id="imgMain" src="../static/images/age_carousel.jpg" alt="Age Gender main image">
        <div class="carousel-caption d-none d-md-block">
            <h1 id="imgHeader">Age & Gender Classifier</h1>
            <h4 id="imgSubhead">CNN trained to classify gender and age group</h4>
        </div>

        <!-- @TODO Modal image popups -->
<!-- @TODO fix spacing on photos and add caption credit where applicable -->
        <section id="about">
            <h1>ABOUT</h1>
            <hr id="underline">
            <h3 id ="subhead">Methods</h3>
            <p>In this portion of our project, we used pre-existing machine learning models to predict the age and gender of a given facial image. 
                The method we used was from a project that used Convolutional Neural Networks to train a model in a Caffe framework by Gil Levi 
                and Tal Hassner<a href="#references"><sup>[1]</sup></a>.</p>
            <h3 id ="subhead">Dataset</h3>
            <p>The project used a dataset from the Adience Benchmark dataset for gender and age classification<a href="#references"><sup>[2]</sup></a>. 
                The dataset comprised of 26,580 images (2GB) of 2,284 subjects. The images were taken from real-world imaging conditions. 
                The images included distortions such as low-resolution or blurry images.</p>
            
                

            <figure class="figure">
                <div class="modal fade bd-example-modal-lg" tabindex="-1" role="dialog" aria-labelledby="myLargeModalLabel" aria-hidden="true">
                    <div class="modal-dialog modal-lg">
                        <div class="modal-content">
                            <img class="shadow-sm p-3 mb-5 bg-white rounded" id="homeImage" src="../static/images/AGdataset.png" alt="Dataset" width="100%">
                        </div>
                    </div>
                </div>          
                <!-- <a href="https://talhassner.github.io/home/projects/Adience/Adience-data.html"> -->
                    <img id="imgContent" src="../static/images/AGdataset.png" alt="Dataset"  data-toggle="modal" data-target=".bd-example-modal-lg"> 
                <!-- </a> -->
                <figcaption class="figure-caption text-right">
                    <p>photo from Adience Benchmark<a href="#references"><sup>[2]</sup></a></p>
                </figcaption>
            </figure>
            <h3 id ="subhead">Classification Groups</h3>
            <p>The dataset images are labeled into eight age categories and two gender categories:</p>
            <figure class="figure">
                <img id="imgContent" class="mx-auto" src="../static/images/AGclassifications.png" alt="Classifications">
                <figcaption class="figure-caption text-right">
                    <p>created by Yuta Yamaguchi &nbsp; &copy; 2019 TEAM EPIC</p>
                </figcaption>
            </figure>
        </section>

        <hr>

        <section id="process">
            <h1>PROCESS</h1>
            <hr id="underline">
            <h3 id ="subhead">CNN Implementation in Caffe</h3>
            <p>The method used a network architecture comprised of three convolutional neural networks with two fully-connected layers. 
                The method was implemented using the Caffe open-source framework, developed by Berkeley AI Research.</p>
            <!-- @TODO add link -->
            <figure class="figure">
                <a href="">
                    <img id="imgContent" src="../static/images/cnn-overview.png" alt="CNN Overview">
                </a>
                <figcaption class="figure-caption text-right">
                    <p>photo from Gil Levi and Tal Hassner<a href="#references"><sup>[1]</sup></a></p>
                </figcaption>
            </figure>
            <h3 id ="subhead">Network Architecture</h3>
            <p>The training for the model was performed on an Amazon GPU machine with 1,536 CUDA cores and 4GB of video memory. 
                Training each network required about 4 hours.</p>
            <figure class="figure">
                <img id="imgContent" src="../static/images/AGnetwork-architecture.png" alt="Network Architecture">
                <figcaption class="figure-caption text-right">
                    <p>created by Yuta Yamaguchi &nbsp; &copy; 2019 TEAM EPIC</p>
                </figcaption>
            </figure>
            <h3 id ="subhead">Performance</h3>
            <p>Table 2 and Table 3 from Levi and Hassner’s paper show the accuracy results from the gender and age classification using their 
                trained models. For age classification, accuracy is measured when the algorithm gives the exact age as well as when the algorithm 
                is off by one adjacent age-group (one age group older or younger).</p>
            <!-- @TODO add link -->
            <figure class="figure">
                <a href="">
                    <img id="imgContent" src="../static/images/AGresults.png" alt="Results (From Gil Levi and Tal Hassner’s paper)">
                </a>
                <figcaption class="figure-caption text-right">
                    <p>photo from Gil Levi and Tal Hassner<a href="#references"><sup>[1]</sup></a></p>
                </figcaption>
            </figure>
            <h3 id ="subhead">Pre-trained Model Application</h3>
            <p>We took the pre-trained Caffe models and used OpenCV’s Deep Neural Networks package to import the neural network models into a 
                Google Colab notebook that runs the prediction script.</p>
            <figure class="figure">
                <img id="imgContent" src="../static/images/AGprocess-overview.png" alt="Process Overview">
                <figcaption class="figure-caption text-right">
                    <p>created by Yuta Yamaguchi &nbsp; &copy; 2019 TEAM EPIC</p>
                </figcaption>
            </figure>
            <h3 id ="subhead">TensorFlow Reimplementation</h3>
            <p>We also found a TensorFlow re-implementation of the Gil/Hassner project using the same Adience dataset and CNN network architecture 
                by GitHub user dpressel<a href="#references"><sup>[3]</sup></a>.</p>
            <figure class="figure">
                <img id="imgContent" src="../static/images/AGtensorflow.png" alt="TensorFlow">
                <figcaption class="figure-caption text-right">
                    <p>created by Yuta Yamaguchi &nbsp; &copy; 2019 TEAM EPIC</p>
                </figcaption>
            </figure>
        </section>

        <hr>
        
        <section id="results">
            <h1>RESULTS</h1>
            <hr id="underline">
            <p>We gathered a group of images for each age and gender groups from the Adience dataset and cropped and flipped the images for testing. 
                We ran the images into both the Caffe and TensorFlow models with the results shown below. The green shade represents correct 
                predictions, yellow shade represents predictions off by one age group, and the red shade represents incorrect predictions with the 
                age group being off 
                by more than one.</p>
            <figure class="figure">
                <img id="imgContent" src="../static/images/AGprediction-results.png" alt="Prediction Results">
                <figcaption class="figure-caption text-right">
                    <p>created by Yuta Yamaguchi &nbsp; &copy; 2019 TEAM EPIC</p>
                </figcaption>
            </figure>
            <p>Overall, the predictions for gender were more accurate, and the age predictions were mostly at least one age group away from the 
                correct age group. Interestingly, the TensorFlow version performed slightly better at predicting the age groups than the Caffe model.</p>
        </section>

        <hr>
        
        <!-- @TODO update to interactive or static depending on time -->
        <section id="testing">
            <h1>TESTING</h1>
            <hr id="underline">
            <p>If interactive does not work - add static images of tests run on model</p>
        </section>
        
        <hr>
        
        <section id="learnings">
            <h1>LEARNINGS</h1>
            <hr id="underline">
            <p>By looking through the dataset images, we found that some images included motion blur, distortions, or exposure issues that may not be 
                ideal for model training. The characteristics of real-world images such as images found on online photo repositories or social media 
                sites may bring challenges in age and gender identification.</p>
            <p>A quick look at the age groups reveals that many ages are left out with no clear explanation as to why. We also found some age groups 
                were hugely underrepresented in the dataset, such as 48-53 and 60+ accounting for less than 5% each.  Meanwhile, the 25-32 age group 
                accounts for nearly 30% - more than double that of an even distribution of the eight groups. The imbalance may offer a cause for both 
                models performing worse in identifying the highest age groups.</p>
            <p>It was impressive to see that relatively high accuracy for age and gender classification can result from a small dataset and a simple 
                CNN network. It would be interesting to see if using a more sophisticated CNN network and a larger dataset would improve prediction 
                results.</p>
            <p>OpenCV posed difficulties installing on a Mac, but it has a useful facial recognition system built-in that helped with cropping and 
                placing text onto images.</p>
        </section>

        <hr>

        <section id="references">
            <h4>References</h4>
            <hr id="underline">
            <ol>
                <li id="refs">
                    Gil Levi and Tal Hassner, <a href="https://talhassner.github.io/home/publication/2015_CVPR"><i>
                        Age and Gender Classification Using Convolutional Neural Networks</i></a>, 
                        IEEE Workshop on Analysis and Modeling of Faces and Gestures (AMFG), at the IEEE Conf. on Computer Vision and Pattern 
                        Recognition (CVPR), Boston, June 2015 <a href="https://github.com/GilLevi/AgeGenderDeepLearning">(Repo)</a>
                        <a href="https://talhassner.github.io/home/projects/cnn_agegender/CVPR2015_CNN_AgeGenderEstimation.pdf">(PDF)</a>
                </li>
                <li id="refs">
                    Eran Eidinger, Roee Enbar, and Tal Hassner, <a href="https://talhassner.github.io/home/publication/2014_IEEE_TIFS"><i>
                        Age and Gender Estimation of Unfiltered Faces</i></a>, Transactions on Information Forensics and Security (IEEE-TIFS), 
                        special issue on Facial Biometrics in the Wild, Volume 9, Issue 12, pages 2170 - 2179, Dec. 2014 
                        <a href="https://talhassner.github.io/home/projects/Adience/EidingerEnbarHassner_tifs.pdf">(PDF)</a>
                </li>
                <li id="refs">
                    Rude Carnie, <a href="https://github.com/dpressel/rude-carnie"><i>Age and Gender Deep Learning with TensorFlow</i></a>
                </li>
            </ol>
        </section>
    </div>
</body>

<!-- FOOTER AREA -->
{% include "footer.html" %}

<!-- SCRIPTS AREA -->
{% include "scripts.html" %}   

</html>